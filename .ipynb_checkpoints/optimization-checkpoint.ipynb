{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化算法\n",
    "\n",
    "### mini-batch gradient descent\n",
    "1. 在一般情况下，bp神经网络进行参数更新的流程是先计算所有样本的误差的均值(cost function)，然后根据该损失函数的梯度来进行参数跟新。但是当样本容量非常大时，所有样本的误差均值的计算量就非常大，从而导致网络更新的速度变得很慢。\n",
    "2. 通过 mini-batch，将原样本分成 k 组。\n",
    "3. 对每组样本，分别计算正向传播和反向传播，训练网络，更新参数。从而只需要计算一个 mini-batch 之后就可以对网络进行更新了，假设样本总量为 m，则对总样本迭代一次就可以对网络更新 $\\frac km$ 次。\n",
    "---\n",
    "\n",
    "\n",
    "### 指数加权平均\n",
    "**计算移动平均值**  \n",
    "假设原数据为$[\\theta_1, \\theta_2, \\theta_3,...,\\theta_n]$，则移动平均值按以下方法计算：\n",
    "\\begin{equation}\n",
    "v_0 = 0\\\\\n",
    "v_1 = 0.9×v_0+0.1×\\theta_1\\\\\n",
    "v_2 = 0.9×v_1+0.1×\\theta_2\\\\\n",
    "...\\\\\n",
    "v_n = 0.9×v_{n-1}+0.1×\\theta_n\n",
    "\\end{equation}\n",
    "对于公式：$v_t=\\beta V_{t-1}+\\beta \\theta_t$，\n",
    "$V_t$ 的值约为 $\\frac {1}{1-\\beta}$ 天的平均值。即上述式子中为10天的平均值。  \n",
    "**偏差修正**  \n",
    "由于在计算前几个平均值的时候，$v_0=0$的影响比较大，可能会使得求得的前几个均值$v_1,v_2,...$的值偏小，所以需要对偏差进行修正。修正的方法如下：  \n",
    "\\begin{equation}\n",
    "v_t=\\frac {v_t}{1-\\beta^t}\n",
    "\\end{equation}\n",
    "随着 t 值的增大，$1-\\beta^t$ 的值趋向于１，所以偏差修正的影响越来越小。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 动量梯度下降法（Gradient descent with momentum）\n",
    "**算法流程**  \n",
    "在当前的 mini-batch 中，计算 dw, db：\n",
    "\\begin{equation}\n",
    "v_{dw}=\\beta v_{dw}(此处为上一个v_{dw}) + (1-\\beta)dw\\\\\n",
    "v_{db}=\\beta v_{db}(此处为上一个v_{db}) + (1-\\beta)db\\\\\n",
    "w = w-\\alpha v_{dw}\\\\\n",
    "b = b-\\alpha v_{db}\n",
    "\\end{equation}\n",
    "在上述算法中，有两个超参数 $\\alpha,\\beta$，$\\beta$的值通常取0.9。在动量梯度下降法中，一般不考虑偏差修正。  \n",
    "**动量梯度下降算法的解释**  \n",
    "在碗形的 cost function 中，指向最低点的路径更新才是有效的，而垂直该方向的路径更新是无效的，在动量梯度下降法中，由于求平均值的作用，无效的路径更新由于符号相反，会相互抵消，留下的是近似的有效的更新路径。  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSprop(root mean square prop)\n",
    "**算法流程**  \n",
    "在当前的 mini-batch 中，计算 dw, db：  \n",
    "\\begin{equation}\n",
    "S_{dw}=\\beta_2 S_{dw}+(1-\\beta_2)(dw)^2\\\\\n",
    "S_{db}=\\beta_2 S_{db}+(1-\\beta_2)(db)^2\\\\\n",
    "w=w-\\alpha \\frac {dw}{\\sqrt {S_{dw}} + \\varepsilon}\\\\\n",
    "b=b-\\alpha \\frac {db}{\\sqrt {S_{db}} + \\varepsilon}\\\\\n",
    "其中\\varepsilon是很小的一个数，为了防止分母为０\n",
    "\\end{equation}\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam optimization algorithom\n",
    "Adam 优化算法是将 momentum 算法和 RMSprop 算法结合。Adam 算法是最常用的一种算法，被广泛用于各种结构的神经网络  \n",
    "**算法流程**  \n",
    "1. 初始化：\n",
    "$v_{dw}=0, v_{db}=0, S_{dw}=0, S_{db}=0$\n",
    "2. 对于 mini-batch 的每次迭代，在当前的 mini-batch 中：  \n",
    " * 计算 $dw, db$,\n",
    " * 执行 momentum 算法（需要进行偏差修正）  \n",
    "\\begin{equation}\n",
    "v_{dw}=\\beta_1 v_{dw}+(1-\\beta_1)dw\\\\\n",
    "v_{db}=\\beta_1 v_{db}+(1-\\beta_1)db\\\\\n",
    "v_{dw}^{correct}=\\frac {v_{dw}}{1-\\beta_1^t}\\\\\n",
    "v_{db}^{correct}=\\frac {v_{db}}{1-\\beta_1^t}\n",
    "\\end{equation}\n",
    " * 执行 RMSprpp 算法（需要进行偏差修正）  \n",
    " \\begin{equation}\n",
    " S_{dw}=\\beta_2 S_{dw}+(1-\\beta_2)(dw)^2\\\\\n",
    " S_{db}=\\beta_2 S_{db}+(1-\\beta_2)(db)^2\\\\\n",
    " S_{dw}^{correct}=\\frac {S_{dw}}{1-\\beta_2^t}\\\\\n",
    " S_{db}^{correct}=\\frac {S_{db}}{1-\\beta_2^t}\n",
    " \\end{equation}\n",
    " * 更新 w,b  \n",
    " \\begin{equation}\n",
    " w=w-\\alpha \\frac {v_{dw}^{correct}}{\\sqrt {S_{dw}^{correct}}+\\varepsilon}\\\\\n",
    " b=b-\\alpha \\frac {v_{db}^{correct}}{\\sqrt {S_{dw}^{correct}}+\\varepsilon}\n",
    " \\end{equation}\n",
    "\n",
    "**超参数的选择**  \n",
    "\n",
    "|hyperparameters|choice|\n",
    "|:-------------:|:----:|\n",
    "|$\\alpha$|需要在程序中进行调试|\n",
    "|$\\beta_1$|一般选0.9|\n",
    "|$\\beta_2$|一般选0.999|\n",
    "|$\\varepsilon$|$10^{-8}$|\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学习率衰减\n",
    "在使用梯度下降算法来更新参数时，由于学习率$\\alpha$的值不变，因此最后的代价函数值会在最低点附近震荡，但是不会收敛到最低点。  \n",
    "\n",
    "**学习率（$\\alpha$）衰减算法**  \n",
    "在训练的过程中，随着迭代次数的增加，逐渐减小$\\alpha$的值  \n",
    "\n",
    "**算法流程**  \n",
    "\\begin{equation}\n",
    "\\alpha=\\frac {1}{1+rate_{dacay} \\times num_{epoch}} \\times \\alpha_0\n",
    "\\end{equation}\n",
    "$epoch_{num}$: the number of iterations  \n",
    "$rate_{dacay}$: dacay rate  \n",
    "\n",
    "**other choice of $\\alpha$:**  \n",
    "\\begin{equation}\n",
    "\\alpha=0.95^{num_{epoch}} \\times \\alpha_0\\\\\n",
    "\\alpha = \\frac {k}{\\sqrt{num_{epoch}}} \\times \\alpha_0\n",
    "\\end{equation}\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization\n",
    "在使用一层逻辑斯蒂回归时，使用样本中心化和方差归一化可以加速训练的过程。但是在深层的网络中，样本中心化和方差归一化之后，经过第一层网络的计算，之后的网络层的输入又变为不是中心化和归一化的了。\n",
    "**question:**  \n",
    "对于每一层的 a 都进行中心化和归一化  \n",
    "**Batch Norm:**  \n",
    "\\begin{equation}\n",
    "\\mu=\\frac 1{m}\\sum z_i\\\\\n",
    "\\sigma^2=\\frac 1{m}\\sum{(\\mu-z_i)}^2\\\\\n",
    "z_{i(norm)}=\\frac {z_i - \\mu}{\\sqrt{\\sigma^2+\\epsilon}}\\\\\n",
    "\\widetilde{z}=\\gamma z_{i(norm)}+\\beta\n",
    "\\end{equation}\n",
    "其中 $\\gamma$ 和 $\\beta$ 不是超参数，而是在反向传播中需要训练的值。通过改变 $\\gamma$ 和 $\\beta$ 的值，可以使每一层的网络拥有不同的平均值和方差。在神经网络的前向传播中，使用 $\\widetilde{z}$ 而不是 $z$ 来计算 $a$ 的值。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
