{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['list_classes', 'train_set_x', 'train_set_y']\n",
      "['list_classes', 'test_set_x', 'test_set_y']\n"
     ]
    }
   ],
   "source": [
    "def get_files(file_dir, type = 'train'):\n",
    "    \"\"\"\n",
    "    从 h5py 格式的文件中读取数据\n",
    "    \"\"\"\n",
    "    \n",
    "    if type == 'train':\n",
    "        with h5py.File(os.path.join(file_dir, 'train_happy.h5')) as f:\n",
    "            print(list(f.keys()))\n",
    "            data = np.array(list(f['train_set_x']))\n",
    "            label = np.array(list(f['train_set_y'])).reshape([-1, 1])\n",
    "            return data, label\n",
    "    \n",
    "    elif type == 'validation':\n",
    "        with h5py.File(os.path.join(file_dir, 'test_happy.h5')) as f:\n",
    "            print(list(f.keys()))\n",
    "            data = np.array(list(f['test_set_x']))\n",
    "            label = np.array(list(f['test_set_y']))\n",
    "            return data, label\n",
    "    \n",
    "    \n",
    "def image2tfrecord(img, label, str_name):\n",
    "    \"\"\"\n",
    "    将图片数据制作成 tfrecord 格式，tfrecord 是谷歌推荐的一种二进制文件格式，\n",
    "    理论上它可以保存任何格式的信息\n",
    "    \n",
    "    Args:\n",
    "        img: 图片数组，4维数组\n",
    "        label: 图片对应的标签\n",
    "        str_name: tfrecord 格式的文件名\n",
    "    \"\"\"\n",
    "    \n",
    "    writer = tf.python_io.TFRecordWriter(str_name)\n",
    "    i = 0\n",
    "    for image in img:\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((64, 64))\n",
    "        image_bytes = image.tobytes()        # 将图片转换成二进制格式\n",
    "        features = {}\n",
    "        \n",
    "        # 保存的是图片的二进制数据\n",
    "        features['image_raw'] = tf.train.Feature(bytes_list = \n",
    "                                    tf.train.BytesList(value = [image_bytes]))\n",
    "        # 保存的是图片的标签，也可以用来保存图片的尺寸信息\n",
    "        features['label'] = tf.train.Feature(int64_list = \n",
    "                                    tf.train.Int64List(value = [int(label[i])]))\n",
    "        i += 1\n",
    "        \n",
    "        # 将所有的 feature 合成 features\n",
    "        tf_features = tf.train.Features(feature = features)\n",
    "        \n",
    "        # 转成 example\n",
    "        tf_example = tf.train.Example(features = tf_features)\n",
    "        \n",
    "        # 序列化样本\n",
    "        tf_serialized = tf_example.SerializeToString()\n",
    "        writer.write(tf_serialized)\n",
    "    \n",
    "    writer.close()\n",
    "        \n",
    "\n",
    "# 将测试图片和验证图片保存为 tfrecords 格式\n",
    "train_imgs, train_labels = get_files('datasets')\n",
    "val_imgs, val_labels = get_files('datasets', 'validation')\n",
    "image2tfrecord(train_imgs, train_labels, 'train.tfrecords')\n",
    "image2tfrecord(val_imgs, val_labels, 'val.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import graph_util\n",
    "\n",
    "def read_and_decode_tfrecord_files(filename, batch_size):\n",
    "    \"\"\"\n",
    "    从 tfrecord 格式的文件中读取出数据，并将其转换成正常的图片和标签\n",
    "    \n",
    "    Args:\n",
    "        filename: tfrecords 文件的文件名（完整的路径）\n",
    "        batch_size: 批大小\n",
    "    Returns:\n",
    "        image_batch: 图片数据 batch\n",
    "        label_batch: label 数据 batch\n",
    "    \"\"\"\n",
    "    \n",
    "    filename_queue = tf.train.string_input_producer([filename])   # 创建一个文件名队列\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    img_features = tf.parse_single_example(serialized_example, \n",
    "                        features = {'label': tf.FixedLenFeature([], tf.int64),\n",
    "                                    'image_raw': tf.FixedLenFeature([], tf.string)})\n",
    "    image = tf.decode_raw(img_features['image_raw'], tf.uint8)    # 从二进制解码到 uint8\n",
    "    image = tf.reshape(image, [224, 224, 3])            # 调整维度\n",
    "    image = tf.cast(image, tf.float32) / 255.0          # 数据格式转换\n",
    "    label = tf.cast(img_features['label'], tf.int32)\n",
    "#     label = tf.reshape(label, [-1, 1])\n",
    "    \n",
    "    image_batch, label_batch = tf.train.batch([image, label],\n",
    "                                              batch_size = batch_size,    # batch的大小\n",
    "                                              num_threads = 64,    # 线程数\n",
    "                                              capacity = 2000)     # 队列中最多能有多少数据\n",
    "    return image_batch, label_batch\n",
    "\n",
    "def my_batch_norm(inputs):\n",
    "    \"\"\"\n",
    "    对输入的数据进行batch normalization\n",
    "    \n",
    "    Args：\n",
    "        inputs：inputs不是上一层的输出，而是 Wx+b，其中 x 才是上一层的输出，\n",
    "                这就解释了为什么 BN 在求均值和方差时是对 [0,1,2] 维的数据进\n",
    "                行求解。\n",
    "    Returns:\n",
    "        inputs: 输入的数据\n",
    "        batch_mean: batch 内的均值\n",
    "        batch_var: batch 内的方差\n",
    "        beta, scale: 需要训练的权重值和偏差值\n",
    "    \"\"\"\n",
    "    \n",
    "    scale = tf.Variable(tf.ones([inputs.get_shape()[-1]]), dtype = tf.float32)\n",
    "    beta = tf.Variable(tf.zeros([inputs.get_shape()[-1]]), dtype = tf.float32)\n",
    "    batch_mean = tf.Variable(tf.zeros([inputs.get_shape()[-1]]), trainable = False)\n",
    "    batch_var = tf.Variable(tf.ones([inputs.get_shape()[-1]]), trainable = False)\n",
    "    \n",
    "    batch_mean, batch_var = tf.nn.moments(inputs, axes = [0, 1, 2])\n",
    "    \n",
    "    return inputs, batch_mean, batch_var, beta, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network():\n",
    "    \"\"\"\n",
    "    搭建完整的网络结构\n",
    "    \"\"\"\n",
    "    \n",
    "    # 网络的输入\n",
    "    x = tf.placeholder(tf.float32, shape = [None, 224, 224, 3], name = 'input')\n",
    "    y = tf.placeholder(tf.int32, shape = [None, 1], name = 'input_label')\n",
    "    lr = tf.placeholder(tf.float32)     # 网络反向传播的学习率，在迭代过程中需要动态改变\n",
    "    \n",
    "    def weight_variable(shape, name):\n",
    "        initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "        return tf.Variable(initial, name = name)\n",
    "    \n",
    "    def bias_variable(shape, name):\n",
    "        initial = tf.constant(0.1, shape = shape)\n",
    "        return tf.Variable(initial, name = name)\n",
    "    \n",
    "    def conv2d(x, w):\n",
    "        return tf.nn.conv2d(x, w, strides=[1, 1, 1, 1], padding = 'SAME')\n",
    "    \n",
    "    def pool(x, pool_type = 'max'):\n",
    "        if 'max' == pool_type:\n",
    "            return tf.nn.max_pool(x, ksize = [1, 2, 2, 1], \n",
    "                                  strides=[1, 2, 2, 1],\n",
    "                                  padding = 'SAME')\n",
    "        else:\n",
    "            return tf.nn.avg_pool(x, ksize = [1, 2, 2, 1],\n",
    "                                  strides = [1, 2, 2, 1],\n",
    "                                  padding = 'SAME')\n",
    "    \n",
    "    # 第一组卷积，包含两个卷积层\n",
    "    with tf.name_scope('conv1_1') as scope:\n",
    "        # 该层没有池化层\n",
    "        W_conv1 = weight_variable([3, 3, 3, 64], 'W_conv1')\n",
    "        b_conv1 = bias_variable([64], 'b_conv1')\n",
    "        Z_conv1 = tf.nn.bias_add(conv2d(x, W_conv1), b_conv1, name = 'Z_conv1')\n",
    "        \n",
    "        # 获取均值和方差\n",
    "        inputs, batch_mean, batch_var, beta, scale = my_batch_norm(Z_conv1)\n",
    "        \n",
    "        \"\"\"\n",
    "        batch normalization 公式：\n",
    "        x = (x - batch_mean) / (sqrt(batch_var) + 0.001)\n",
    "        x_out = x * scale + beta\n",
    "        \"\"\"\n",
    "        conv_batch_norm = tf.nn.batch_normalization(inputs, batch_mean, batch_var, beta, scale, 0.001)\n",
    "        A_conv1 = tf.nn.relu(conv_batch_norm, name = 'A_conv1')\n",
    "        \n",
    "    with tf.name_scope('conv1_2') as scope:\n",
    "        W_conv2 = weight_variable([3, 3, 64, 64], 'W_conv2')\n",
    "        b_conv2 = bias_variable([64], 'b_conv2')\n",
    "        Z_conv2 = tf.nn.bias_add(conv2d(A_conv1, W_conv2), b_conv2, name = 'Z_conv2')\n",
    "        \n",
    "        # batch normalization\n",
    "        inputs, batch_mean, batch_var, beta, scale = my_batch_norm(Z_conv2)\n",
    "        conv_batch_norm = tf.nn.batch_normalization(inputs, batch_mean, batch_var, beta, scale, 0.001)\n",
    "        A_conv2 = tf.nn.relu(conv_batch_norm, name = 'A_conv2')\n",
    "        pool1 = pool(A_conv2)   # 结束完一组卷积之后进行池化\n",
    "        \n",
    "    # 第二组卷积，包含两个卷积层\n",
    "    with tf.name_scope('conv2_1') as scope:\n",
    "        W_conv3 = weight_variable([3, 3, 64, 128], 'W_conv3')\n",
    "        b_conv3 = bias_variable([128], 'b_conv3')\n",
    "        Z_conv3 = tf.nn.bias_add(conv2d(pool1, W_conv3), b_conv3, name = 'Z_conv3')\n",
    "        inputs, batch_mean, batch_var, beta, scale = my_batch_norm(Z_conv3)\n",
    "        conv_batch_norm = tf.nn.batch_normalization(inputs, batch_mean, batch_var, beta, scale, 0.001)\n",
    "        A_conv3 = tf.nn.relu(conv_batch_norm, name = 'A_conv3')\n",
    "        \n",
    "    with tf.name_scope('conv2_2') as scope:\n",
    "        W_conv4 = weight_variable([3, 3, 128, 128], 'W_conv4')\n",
    "        b_conv4 = bias_variable([128], 'b_conv4')\n",
    "        Z_conv4 = tf.nn.bias_add(conv2d(A_conv3, W_conv4), b_conv4, name = 'Z_conv4')\n",
    "        inputs, batch_mean, batch_var, beta, scale = my_batch_norm(Z_conv4)\n",
    "        conv_batch_norm = tf.nn.batch_normalization(inputs, batch_mean, batch_var, beta, scale, 0.001)\n",
    "        A_conv4 = tf.nn.relu(conv_batch_norm, name = 'A_conv4')\n",
    "        pool2 = pool(A_conv4)\n",
    "        \n",
    "    # 第三组卷积，包含两个卷积层\n",
    "    with tf.name_scope('conv3_1') as scope:\n",
    "        W_conv5 = weight_variable([3, 3, 128, 256], 'W_conv5')\n",
    "        b_conv5 = bias_variable([256], 'b_conv5')\n",
    "        Z_conv5 = tf.nn.bias_add(conv2d(pool2, W_conv5), b_conv5, name = 'Z_conv5')\n",
    "        inputs, batch_mean, batch_var, beta, scale = my_batch_norm(Z_conv5)\n",
    "        conv_batch_norm = tf.nn.batch_normalization(inputs, batch_mean, batch_var, beta, scale, 0.001)\n",
    "        A_conv5 = tf.nn.relu(conv_batch_norm, name = 'A_conv5')\n",
    "        \n",
    "    with tf.name_scope('conv3_2') as scope:\n",
    "        W_conv6 = weight_variable([3, 3, 256, 256], 'W_conv6')\n",
    "        b_conv6 = bias_variable([256], 'b_conv6')\n",
    "        Z_conv6 = tf.nn.bias_add(conv2d(A_conv5, W_conv6), b_conv6, name = 'Z_conv6')\n",
    "        inputs, batch_mean, batch_var, beta, scale = my_batch_norm(Z_conv6)\n",
    "        conv_batch_norm = tf.nn.batch_normalization(inputs, batch_mean, batch_var, beta, scale, 0.001)\n",
    "        A_conv6 = tf.nn.relu(conv_batch_norm, name = 'A_conv6')\n",
    "        pool3 = pool(A_conv6)\n",
    "        \n",
    "    # 第四组卷积\n",
    "    # 第五组卷积\n",
    "    \n",
    "    # fc6\n",
    "    with tf.name_scope('fc6') as scope:\n",
    "        shape = int(np.prod(pool3.get_shape()[1:]))\n",
    "        W_fc6 = weight_variable([shape, 128], 'W_fc6')\n",
    "        b_fc6 = bias_variable([128], 'b_fc6')\n",
    "        pool_flat = tf.reshape(pool3, [-1, shape])\n",
    "        A_fc6 = tf.nn.relu(tf.matmul(pool_flat, W_fc6) + b_fc6, name = 'A_fc6')\n",
    "        \n",
    "    # fc7\n",
    "    with tf.name_scope('fc7') as scope:\n",
    "        W_fc7 = weight_variable([128, 64], 'W_fc7')\n",
    "        b_fc7 = bias_variable([64], 'b_fc7')\n",
    "        A_fc7 = tf.nn.relu(tf.matmul(A_fc6, W_fc7) + b_fc7, name = 'A_fc7')\n",
    "        \n",
    "    # fc8\n",
    "    with tf.name_scope('fc8') as scope:\n",
    "        W_fc8 = weight_variable([64, 1], 'W_fc8')\n",
    "        b_fc8 = bias_variable([1], 'b_fc8')\n",
    "        A_fc8 = tf.nn.sigmoid(tf.matmul(A_fc7, W_fc8) + b_fc8, name = 'A_fc8')\n",
    "        \n",
    "    # calculate cost and optimizer the model\n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.cast(y,tf.float32), \n",
    "                                                                  logits=A_fc8))\n",
    "    predict = tf.cast(A_fc8 > 0.5, tf.int32)      # 给出预测值\n",
    "    accuracy = tf.reduce_mean(predict)            # 计算预测的准确率   \n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cost)     # 更新模型参数\n",
    "    \n",
    "    return dict(x = x, \n",
    "                y = y,\n",
    "                lr = lr,\n",
    "                cost = cost, \n",
    "                accuracy = accuracy,\n",
    "                train_step = train_step)\n",
    "\n",
    "graph = build_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(graph, batch_size, num_epoches, pd_file_path):\n",
    "    \"\"\"\n",
    "    对传入该函数的网络进行训练\n",
    "    \n",
    "    Args:\n",
    "        graph: 通过 build_network 函数构建的计算图\n",
    "        batch_size: 批大小\n",
    "        num_epoches: 网络迭代的次数\n",
    "        pd_file_path: pd 文件保存的路径\n",
    "    \"\"\"\n",
    "    \n",
    "    image_batch, label_batch = read_and_decode_tfrecord_files(filename = 'train.tfrecords',\n",
    "                                                              batch_size = batch_size)\n",
    "    val_image_batch, val_label_batch = read_and_decode_tfrecord_files(filename = 'val.tfrecords',\n",
    "                                                                      batch_size = batch_size)\n",
    "    init = tf.global_variables_initializer()     # 变量初始化\n",
    "    \n",
    "    with tf.Session() as sess:                   # 创建会话\n",
    "        sess.run(init)\n",
    "        \n",
    "        \"\"\"\n",
    "        在 tensorflow 中，当文件名队列中的元素取完之后，会抛出一个 OutofRangeError 异常\n",
    "        \"\"\"\n",
    "        coord = tf.train.Coordinator() \n",
    "        threads = tf.train.start_queue_runners(sess = sess, coord = coord)   # 启动内存队列\n",
    "        try:\n",
    "            for epoch in range(num_epoches):     # 执行模型的迭代更新，并检查是否出现异常\n",
    "                train_data, train_label = sess.run([image_batch, label_batch])\n",
    "                train_label = train_label.reshape([-1, 1])\n",
    "                cost_val, accuracy_train, _ = sess.run([graph['cost'],\n",
    "                                                        graph['accuracy'],\n",
    "                                                        graph['train_step']],\n",
    "                                                       feed_dict = {graph['x']: train_data,\n",
    "                                                                    graph['y']: train_label,\n",
    "                                                                    graph['lr']: 1e-4})\n",
    "                print('Cost of Iter ',epoch,' : ',cost_val)\n",
    "                print('Train accuracy: ',accuracy_train)\n",
    "                \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('Training has finished')\n",
    "        finally:\n",
    "            coord.request_stop()\n",
    "        \n",
    "        coord.join(threads)         # 把开启的线程加入主线程，防止主线程运行结束之后直接退出\n",
    "        print('All threads are stopped!')\n",
    "        \n",
    "\n",
    "train_network(graph, 10, 20, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
